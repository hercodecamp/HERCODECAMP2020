{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "\n",
    "This notebook walks through both concepts and libraries that will be important for the intro to data science project. \n",
    "\n",
    "We will cover: \n",
    "- using libraries: \n",
    "    - numpy, pandas, matplotlib, collections, tqdm, sklearn\n",
    "- list comprehensions, enumerate, 2D list slicing \n",
    "- linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Library? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A library is a collection of functions, usually written by awesome people in the Python community. \n",
    "Although some libraries can seem big and complicated, they actually are easy to use and create. \n",
    "We’re going to quickly show you how you can make your own library, \n",
    "and then we’ll show you how to download and use popular python libraries.\n",
    "\n",
    "#### note: this has to be done as a separate py file.. code below is to copy-paste :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_num(x: float, y: float) -> float:\n",
    "    ''' Simple function that sums two numbers x and y '''\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def diff_num(x: float, y: float) -> float: \n",
    "    ''' Simple function that sums two numbers x and y '''   \n",
    "    return x - y\n",
    "\n",
    "def count(x: int) -> None:\n",
    "    ''' Sequential counting '''\n",
    "    \n",
    "    print('Let\\'s count together!')\n",
    "    \n",
    "    for i in range(x):\n",
    "        print(f'Step: {i}')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our own library saved as a python file... but how do we use these functions? We will have to tell python to import any libraries into our existing code. Let's look at how we can use the import statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 21 \n",
      "difference: -1\n"
     ]
    }
   ],
   "source": [
    "# this first example imports *everything* from the library \n",
    "# (note for my OOP friends; this includes private functions -> use from mylibrary import * to import public only)\n",
    "\n",
    "import mylibrary\n",
    "\n",
    "x = 10\n",
    "y = 11 \n",
    "\n",
    "a = mylibrary.sum_num(x, y)\n",
    "b = mylibrary.diff_num(x, y)\n",
    "\n",
    "print(f'sum: {a} \\ndifference: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 21 \n",
      "difference: -1\n"
     ]
    }
   ],
   "source": [
    "# what if you don't want to write a long name like mylibrary everytime? You can alias the library name\n",
    "\n",
    "import mylibrary as ml\n",
    "\n",
    "x = 10\n",
    "y = 11 \n",
    "\n",
    "a = ml.sum_num(x, y)\n",
    "b = ml.diff_num(x, y)\n",
    "\n",
    "print(f'sum: {a} \\ndifference: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 21\n"
     ]
    }
   ],
   "source": [
    "# We can save some memory by only importing functions we need in a file by using the from syntax\n",
    "\n",
    "from mylibrary import sum_num\n",
    "\n",
    "x = 10 \n",
    "y = 11\n",
    "\n",
    "a = mylibrary.sum_num(x, y)\n",
    "\n",
    "print(f'sum: {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we see that importing libraries just means you're importing functions stored in other files. You now know how to use the import statement to import entire libraries, or just functions that you want from the libraries. We will be introducing 3 very useful (and commonly used) libraries in the next section that will help us analyze our data quickly and efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Using Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start with an example of a one-dimensional data set -- the ages of a group of friends. We can represent this as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 17, 18, 19, 16, 20]\n"
     ]
    }
   ],
   "source": [
    "ages = [17, 17, 18, 19, 16, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we know how lists work. Although they're nice, they can be very inefficient, especially when the lists get very long. Numpy (NUMerical PYthon) gives us a way to represent these lists as an array. You can think of it as casting one type to another (e.g., int('5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pprint import pprint\n",
    "\n",
    "# use np.array to make a copy of the original ages list\n",
    "ages_np_copy = np.array(ages)\n",
    "\n",
    "# or use np.asarray to manipulate the original ages list\n",
    "ages_np_inplace = np.asarray(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how we addressed the efficiency of a numpy array vs a list? This comes in handy when we want to work with multi-dimensional arrays. \n",
    "\n",
    "Say we want to know the height of everyone in this group and see if height is correlated to age. We would have to make two separate lists with regular python, but we can make a 2-dimensional array, or data table, with numpy:\n",
    "\n",
    "\n",
    "##### note: we use pprint (a.k.a \"pretty-print\") because it shows us that we're dealing with a list now and prints the data in a prettier way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 17,  17,  18,  19,  16,  20],\n",
      "       [165, 170, 169, 150, 167, 171]])\n"
     ]
    }
   ],
   "source": [
    "heights = [165, 170, 169, 150, 167, 171]\n",
    "friends = np.asarray([ages, heights])\n",
    "pprint(friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our ‘friends’ array is structured as a table with two rows and three columns, where the first row is the age of each friend and the second row is the height (in centimetres) of each friend. \n",
    "\n",
    "What if we wanted to change the view of this array -- it makes more sense to have the ages be rows, and the height be a column. We can use the transpose function to make the columns be rows, and rows be columns. Let's see what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 17, 165],\n",
      "       [ 17, 170],\n",
      "       [ 18, 169],\n",
      "       [ 19, 150],\n",
      "       [ 16, 167],\n",
      "       [ 20, 171]])\n"
     ]
    }
   ],
   "source": [
    "friends_transpose = friends.transpose()\n",
    "pprint(friends_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the first column is for age and the second column is for height, and each row is a friend. This is usually how we work with data: each variable gets its own column, and each observation gets its own row.\n",
    "\n",
    "Numpy lets us calculate statistics about our data, such as finding the mean age and height in the friend group. To do this, we have to tell numpy where we want to calculate our statistics by defining \"axis\". The axis argument is just a fancy way of saying row (axis = 0) or column (axis = 1). \n",
    "\n",
    "We want to find the average among the ages and heights. If you do this by hand, you would sum each column separately, and divide over the number of _rows_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.83333333, 165.33333333])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(friends_transpose, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is powerful for working with numbers, but it can handle other types of data, too. It would be useful to see which row refers to which friend without having to remember. Let’s fix that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([['Emily', '17', '165'],\n",
      "       ['Shraddha', '17', '170'],\n",
      "       ['Anne', '18', '169'],\n",
      "       ['Jess', '19', '150'],\n",
      "       ['Riley', '16', '167'],\n",
      "       ['Nicola', '20', '171']], dtype='<U8')\n"
     ]
    }
   ],
   "source": [
    "names = ['Emily', 'Shraddha', 'Anne', 'Jess', 'Riley', 'Nicola']\n",
    "friends_names = np.asarray([names, ages, heights]).transpose()\n",
    "\n",
    "pprint(friends_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have names in our data, we can’t use ‘np.mean’ on all of the columns, since the first column isn’t full of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-09bc80acb295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfriends_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2920\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "np.mean(friends_names, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall in Python Lists, we can using \"slicing\" notation to access elements with [start:stop] notation. \n",
    "Since we're working with two dimensional arrays now, we need to modify our slicing notation to the following: \n",
    "\n",
    "[row_start:row_stop, col_start:col_stop]\n",
    "\n",
    "Remember that python starts counting at 0 instead of 1. We want to include every row, so we will use ‘:’ which translates to start at the beginning row and go until the last row, then a list of columns we want second (after the comma):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.83333333, 165.33333333])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we include the .astype(int) to make sure our slices contain the correct dtype\n",
    "np.mean(friends_names[:,[1,2]].astype(int), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy has a long list of functions other than just mean. If you look at the documentation (https://numpy.org/doc/) you'll find *all* of numpys functions :-) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is another library that was built to work with numpy. Importantly, Pandas lets you organize and work with data that has mixed types like strings, booleans, and numbers. Remember how we had to cast the friends_names array earlier? Pandas doesn't need to do this. Let’s load our data into pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Names Ages Heights\n",
      "0     Emily   17     165\n",
      "1  Shraddha   17     170\n",
      "2      Anne   18     169\n",
      "3      Jess   19     150\n",
      "4     Riley   16     167\n",
      "5    Nicola   20     171\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# we can specify a list of column names we want, just to keep us organized\n",
    "friends_pd = pd.DataFrame(friends_names, columns=['Names', 'Ages', 'Heights'])\n",
    "pprint(friends_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Notice how pandas was automatically able to figure out the columns and the rows? This looks a lot tidier than it did with numpy! Pandas works well with long-form data, where each column is a variable and each row is an observation. \n",
    "\n",
    "With pandas dataframes each column is considered a separate series, which is similar to a python list. You can think about a pandas dataframe as a collection of lists.\n",
    "\n",
    "One of the biggest advantages of using pandas instead of a bunch of numpy lists is that the library comes with a lot of really fast and useful functions pre-built. When you have a lot of data to work with, speed and efficiency of your functions becomes very important.\n",
    "\n",
    "Let's look at accessing one column and one row: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names      Emily\n",
      "Ages          17\n",
      "Heights      165\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "0    165\n",
      "1    170\n",
      "2    169\n",
      "3    150\n",
      "4    167\n",
      "5    171\n",
      "Name: Heights, dtype: object\n",
      "\n",
      "\n",
      "165.33333333333334\n"
     ]
    }
   ],
   "source": [
    "# iloc -> \"integer location\", refers to the first (0th) row\n",
    "pprint(friends_pd.iloc[0])\n",
    "print('\\n')\n",
    "\n",
    "# not using iloc, you're indexing a column\n",
    "pprint(friends_pd['Heights'])\n",
    "print('\\n')\n",
    "\n",
    "# no casting necessary!\n",
    "pprint(np.mean(friends_pd['Heights'].apply(lambda x: int(x))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s work with some other data. Download this file pets.csv and save it to the computer desktop (you can download and read datasets from anywhere on your computer, but for today let’s use the desktop folder). The dataset is stored as a ‘.csv’ file, which stands for ‘comma-separated values’. This means commas are used to separate the columns. The first few rows look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Animal           Name  Age  Weight  Color\n",
      "0    Dog          Angel   12      99  black\n",
      "1    Dog          Matty    3      15  brown\n",
      "2    Dog  Michaelangelo    9     120  white\n",
      "3    Cat        Cupcake   15      10   grey\n",
      "4    Cat          Louis    6      12  brown\n"
     ]
    }
   ],
   "source": [
    "PATH = '/Users/chantal/Desktop/HERCC_ds/menu_cost_prediction/pets.csv'\n",
    "pets = pd.read_csv(PATH)\n",
    "pprint(pets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use special commands that let the computer know that the columns are separated by commas, so when we load it into python, the commas are removed and it looks nice and clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is nice and lined up, but there are numbers on the left that weren’t in the file. This ‘index’ is added by pandas to make it easier to see what row you’re working with, Notice how the column names (Animal, Name, Age, Weight, Color) do not have a number. This is because the default for pd.read_csv is to assume that the very first row in the file is the column names. If we had a dataset that didn’t have column names, we would have to specify this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0              1    2       3      4\n",
      "0  Animal           Name  Age  Weight  Color\n",
      "1     Dog          Angel   12      99  black\n",
      "2     Dog          Matty    3      15  brown\n",
      "3     Dog  Michaelangelo    9     120  white\n",
      "4     Cat        Cupcake   15      10   grey\n",
      "5     Cat          Louis    6      12  brown\n"
     ]
    }
   ],
   "source": [
    "pets_no_names = pd.read_csv(PATH, header=None)\n",
    "pprint(pets_no_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the column names are numbered as row 0, and each column is numbered as well. If we tried to do analysis on our data like this, we would probably get a lot of error messages because the columns are now a mix of numbers and characters. It’s important to check your data after you loaded it to make sure it looks ok. If you know a bit about your data beforehand, you can check the shape of it to see if it matches what you expect (or if you don’t know what to expect, you can find out!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value is the number of rows and the second value is the number of columns.\n",
    "\n",
    "It might be easier to think about our data if we label the rows with the names of the pets instead of numbers. We can do this with any column, but it’s best to use columns where each value is unique. That way we can specify exactly which row we are interested in. Let’s change the row indexing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Animal  Age  Weight  Color\n",
      "Name                                    \n",
      "Angel            Dog   12      99  black\n",
      "Matty            Dog    3      15  brown\n",
      "Michaelangelo    Dog    9     120  white\n",
      "Cupcake          Cat   15      10   grey\n",
      "Louis            Cat    6      12  brown\n"
     ]
    }
   ],
   "source": [
    "pets_named = pets.set_index('Name')\n",
    "pprint(pets_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Name column has been removed, and now the rows are labeled with the appropriate names. If we wanted to look at just the details about Matty, we can do this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Animal      Dog\n",
       "Age           3\n",
       "Weight       15\n",
       "Color     brown\n",
       "Name: Matty, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_named.loc['Matty', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ‘loc’ function selects the data at the specified location, so in this case, at the row named Matty and all of the columns (indicated by ‘:’). We can grab a column of data in a similar fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Angel             99\n",
       "Matty             15\n",
       "Michaelangelo    120\n",
       "Cupcake           10\n",
       "Louis             12\n",
       "Name: Weight, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_named.loc[:, 'Weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave us the values of the weight of each pet. If we wanted to be more specific and say we’re only interested in finding out the weight of Matty, we could do that like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_named.loc['Matty', 'Weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we didn’t name the rows or columns of our data, we can use a similar function ‘iloc’ that uses the numbered indexes. First, lets double check the row and column numbers of where Matty’s weight is stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0              1    2       3      4\n",
      "0  Animal           Name  Age  Weight  Color\n",
      "1     Dog          Angel   12      99  black\n",
      "2     Dog          Matty    3      15  brown\n",
      "3     Dog  Michaelangelo    9     120  white\n",
      "4     Cat        Cupcake   15      10   grey\n",
      "5     Cat          Louis    6      12  brown\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'15'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pets_no_names)\n",
    "\n",
    "# We want row number 2 and column number 3:\n",
    "\n",
    "pets_no_names.iloc[2, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s add some new columns to our dataset. We will make a list of which family each pet belongs to and attach them to our existing dataframe by creating a new column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-0bca827e50ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpets_named\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Family'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Smith'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Liu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Douglas'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Khan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3486\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3487\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3564\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3565\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3749\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3751\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "pets_named['Family'] = ['Smith', 'Liu', 'Douglas', 'Khan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops, we got an error! When we add new rows or columns, they have to match the dimensions of the dataframe. We forgot to include Louise’s family!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_named['Family'] = ['Smith', 'Liu', 'Douglas', 'Khan', 'Garcia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s better. Let’s also add how long each family has had their pet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_owned = [10, 3, 8, 2, 4]\n",
    "pets_named['Years_owned'] = years_owned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create new columns based on information in existing columns. We can add a column for how old each pet was when it was adopted by each family by subtracting the Years_Owned column from the Age column using the ‘assign’ function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_updated = pets_named.assign(Adoption_age = pets_named['Age'] - pets_named['Years_owned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we no longer need a column and want to keep the size of our dataframe nice and manageable, we can remove columns with the ‘drop’ function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Animal  Age  Weight   Family  Years_owned  Adoption_age\n",
      "Name                                                                 \n",
      "Angel            Dog   12      99    Smith           10             2\n",
      "Matty            Dog    3      15      Liu            3             0\n",
      "Michaelangelo    Dog    9     120  Douglas            8             1\n",
      "Cupcake          Cat   15      10     Khan            2            13\n",
      "Louis            Cat    6      12   Garcia            4             2\n"
     ]
    }
   ],
   "source": [
    "pets_less = pets_updated.drop(columns='Color')\n",
    "pprint(pets_less)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other useful Libraries: collections, tqdm, Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, there are a few other cool libraries we can make use of in our data science projects. I'll demonstrate them briefly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011967551000452659\n",
      "1.4199160369998935\n"
     ]
    }
   ],
   "source": [
    "# collections provides faster implementations of structures than the default python\n",
    "import timeit\n",
    "\n",
    "# deque structure\n",
    "print(timeit.timeit(stmt='d.pop()',setup='from collections import deque; \\\n",
    "                                          d = deque(range(100000))',number=99999))\n",
    "\n",
    "# list structure\n",
    "print(timeit.timeit(stmt='l.pop(0)',setup='l = list(range(100000))',number=99999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|█▍        | 146023/1000000 [00:00<00:00, 1460213.99it/s]\u001b[A\n",
      " 29%|██▊       | 285867/1000000 [00:00<00:00, 1441112.42it/s]\u001b[A\n",
      " 48%|████▊     | 477695/1000000 [00:00<00:00, 1557326.28it/s]\u001b[A\n",
      " 67%|██████▋   | 667380/1000000 [00:00<00:00, 1645693.29it/s]\u001b[A\n",
      " 86%|████████▋ | 864830/1000000 [00:00<00:00, 1732231.44it/s]\u001b[A\n",
      "  2%|▏         | 19759945/1000000000 [00:20<06:16, 2606996.39it/s]"
     ]
    }
   ],
   "source": [
    "# tqdm is a cool progress bar wrapper around your for-loops \n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(1000000)):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn is a popular library for many machine learning and data science applications. We'll cover this library in depth in the Linear Regression section, but for now, you can take a look at the documentation page: \n",
    "\n",
    "https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Lists (... Beyond the Basics)\n",
    "\n",
    "#### NOTE: cover string.split() in the refresher section!!!!! and working with strings in general, maybe the reading and writing to files as well???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehensions are a cool, pythonic way of quickly manipulating lists in python. They basically take a for loop and condense it into one line. Let's take a look at how to jump between a for loop and a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9]\n",
      "[3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' general structure for list comprehensions: [*modify x* for *each x* in my_list] '''\n",
    "\n",
    "my_list_loop = [1, 2, 3, 4, 5, 6, 7]\n",
    "my_list_comp = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# lets add one to each element with a for loop: \n",
    "\n",
    "# recall that enumerate returns the index AND the value in the list\n",
    "for index, num in enumerate(my_list_loop):\n",
    "    my_list_loop[index] = num+1\n",
    "\n",
    "pprint(my_list)\n",
    "\n",
    "# now lets do it using list comprehensions\n",
    "my_list_comp = [num+1 for num in my_list_comp]\n",
    "\n",
    "pprint(my_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Basics: Introducing Linear Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
